{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2236708,"sourceType":"datasetVersion","datasetId":1343913}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-14T09:47:04.649233Z","iopub.execute_input":"2023-11-14T09:47:04.649539Z","iopub.status.idle":"2023-11-14T09:47:11.480511Z","shell.execute_reply.started":"2023-11-14T09:47:04.649511Z","shell.execute_reply":"2023-11-14T09:47:11.479592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import CategoricalAccuracy\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-11-14T09:47:11.482196Z","iopub.execute_input":"2023-11-14T09:47:11.482628Z","iopub.status.idle":"2023-11-14T09:47:24.396586Z","shell.execute_reply.started":"2023-11-14T09:47:11.482601Z","shell.execute_reply":"2023-11-14T09:47:24.395751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nsource_path = '/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set'\n\nsource_path_no = os.path.join(source_path, 'Healthy')\nsource_path_yes = os.path.join(source_path, 'Brain Tumor')\n\n# os.listdir returns a list containing all files under the given path\nprint(f\"There are {len(os.listdir(source_path_yes))} Tumor Images.\")\nprint(f\"There are {len(os.listdir(source_path_no))} Non Tumor Images.\")","metadata":{"execution":{"iopub.status.busy":"2023-11-14T09:47:24.397530Z","iopub.execute_input":"2023-11-14T09:47:24.398044Z","iopub.status.idle":"2023-11-14T09:47:24.408888Z","shell.execute_reply.started":"2023-11-14T09:47:24.398018Z","shell.execute_reply":"2023-11-14T09:47:24.406405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\n\n# Create empty lists to store the images and their corresponding labels\nimages = []\nlabels = []\n\n# Define the target size for resizing\ntarget_size = (256, 256)\n\n# Read and preprocess positive (yes) cases\nfor image_file in os.listdir(source_path_yes):\n    image_path = os.path.join(source_path_yes, image_file)\n    image = cv2.imread(image_path)\n    # Resize the image to the target size (256x256)\n    image = cv2.resize(image, target_size)\n    # Normalize the image by cropping (center crop)\n    h, w = image.shape[:2]\n    crop_start_x = (w - 224) // 2\n    crop_start_y = (h - 224) // 2\n    image = image[crop_start_y:crop_start_y+224, crop_start_x:crop_start_x+224]\n    # Convert BGR to RGB (if needed)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    # Append the processed image and its label to the lists\n    images.append(image)\n    labels.append(1)  # 1 for positive cases\n\n# Read and preprocess negative (no) cases\nfor image_file in os.listdir(source_path_no):\n    image_path = os.path.join(source_path_no, image_file)\n    image = cv2.imread(image_path)\n    # Resize the image to the target size (256x256)\n    image = cv2.resize(image, target_size)\n    # Normalize the image by cropping (center crop)\n    h, w = image.shape[:2]\n    crop_start_x = (w - 224) // 2\n    crop_start_y = (h - 224) // 2\n    image = image[crop_start_y:crop_start_y+224, crop_start_x:crop_start_x+224]\n    # Convert BGR to RGB (if needed)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    # Append the processed image and its label to the lists\n    images.append(image)\n    labels.append(0)  # 0 for negative cases\n\n# Convert the image and label lists to NumPy arrays for machine learning\nX = np.array(images)\ny = np.array(labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display examples of \"Brain Tumor\" images\nfig, axes = plt.subplots(2, 3, figsize=(12, 8))\nfig.suptitle(\"Examples of 'Positive and Negative' Image Classes\", fontsize=16)\nfor i in range(3):\n    axes[0, i].imshow(X[y == 1][i])  # Display the first 3 \"yes\" images\n    axes[0, i].set_title(\"Positive Case\")\n    axes[0, i].axis('off')\n\n# Display examples of \"Healthy\" images\nfor i in range(3):\n    axes[1, i].imshow(X[y == 0][i])  # Display the first 3 \"no\" images\n    axes[1, i].set_title(\"Negative Case\")\n    axes[1, i].axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T09:48:14.795338Z","iopub.execute_input":"2023-11-14T09:48:14.795717Z","iopub.status.idle":"2023-11-14T09:48:16.149243Z","shell.execute_reply.started":"2023-11-14T09:48:14.795684Z","shell.execute_reply":"2023-11-14T09:48:16.148110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"source_tumor_dir = '/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set/Brain Tumor'\nsource_healthy_dir = '/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set/Healthy'\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T09:53:15.875480Z","iopub.execute_input":"2023-11-14T09:53:15.876202Z","iopub.status.idle":"2023-11-14T09:53:15.880608Z","shell.execute_reply.started":"2023-11-14T09:53:15.876153Z","shell.execute_reply":"2023-11-14T09:53:15.879555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the train and test directories\n\n\ntrain_directory = '/kaggle/working/train'\ntest_directory = '/kaggle/working/test'\nvalidation_directory = '/kaggle/working/validation'\n\nos.makedirs(train_directory, exist_ok=True)\nos.makedirs(test_directory, exist_ok=True)\nos.makedirs(validation_directory, exist_ok=True)\n\n# Define the destination directories for train, validation, and test sets\ntrain_healthy_dir = '/kaggle/working/train/healthy'\nvalidation_healthy_dir = '/kaggle/working/validation/healthy'\ntest_healthy_dir = '/kaggle/working/test/healthy'\n\ntrain_tumor_dir = '/kaggle/working/train/tumor'\nvalidation_tumor_dir = '/kaggle/working/validation/tumor'\ntest_tumor_dir = '/kaggle/working/test/tumor'\n\n# Create destination directories if they don't exist\nfor directory in [train_healthy_dir, validation_healthy_dir, test_healthy_dir,\n                  train_tumor_dir, validation_tumor_dir, test_tumor_dir]:\n    os.makedirs(directory, exist_ok=True)\n\ndef copy_and_split_images(source_dir, train_dir, validation_dir, test_dir, split_ratio=(0.8, 0.1)):\n    # List of image files in the source directory\n    source_files = os.listdir(source_dir)\n    # Shuffle the list to randomize\n    random.shuffle(source_files)\n\n    # Calculate split points\n    train_split = int(len(source_files) * split_ratio[0])\n    validation_split = train_split + int(len(source_files) * split_ratio[1])\n\n    # Split the files into train, validation, and test sets\n    train_files = source_files[:train_split]\n    validation_files = source_files[train_split:validation_split]\n    test_files = source_files[validation_split:]\n\n    # Copy train files to the train directory\n    for file in train_files:\n        src = os.path.join(source_dir, file)\n        dst = os.path.join(train_dir, file)\n        shutil.copy(src, dst)\n\n    # Copy validation files to the validation directory\n    for file in validation_files:\n        src = os.path.join(source_dir, file)\n        dst = os.path.join(validation_dir, file)\n        shutil.copy(src, dst)\n\n    # Copy test files to the test directory\n    for file in test_files:\n        src = os.path.join(source_dir, file)\n        dst = os.path.join(test_dir, file)\n        shutil.copy(src, dst)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T09:48:16.150752Z","iopub.execute_input":"2023-11-14T09:48:16.151080Z","iopub.status.idle":"2023-11-14T09:48:16.164055Z","shell.execute_reply.started":"2023-11-14T09:48:16.151050Z","shell.execute_reply":"2023-11-14T09:48:16.163071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport os\nimport shutil\n# Copy and split tumor images\ncopy_and_split_images(source_tumor_dir, train_tumor_dir, validation_tumor_dir, test_tumor_dir)\n\n# Copy and split healthy images\ncopy_and_split_images(source_healthy_dir, train_healthy_dir, validation_healthy_dir, test_healthy_dir)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T09:53:20.358685Z","iopub.execute_input":"2023-11-14T09:53:20.359567Z","iopub.status.idle":"2023-11-14T09:53:25.484431Z","shell.execute_reply.started":"2023-11-14T09:53:20.359533Z","shell.execute_reply":"2023-11-14T09:53:25.483459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"There are {len(os.listdir(train_tumor_dir))} images of tumor for training\")\nprint(f\"There are {len(os.listdir(train_healthy_dir))} non tumor for training\")\nprint(f\"There are {len(os.listdir(validation_tumor_dir))} images of tumor for validation\")\nprint(f\"There are {len(os.listdir(validation_healthy_dir))} non tumor for validation\")\nprint(f\"There are {len(os.listdir(test_healthy_dir))} non tumor for testing\")\nprint(f\"There are {len(os.listdir(test_tumor_dir))} tumor images for testing\")","metadata":{"execution":{"iopub.status.busy":"2023-11-14T09:55:03.577016Z","iopub.execute_input":"2023-11-14T09:55:03.577385Z","iopub.status.idle":"2023-11-14T09:55:03.587446Z","shell.execute_reply.started":"2023-11-14T09:55:03.577356Z","shell.execute_reply":"2023-11-14T09:55:03.586500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(horizontal_flip= True,\n                                  width_shift_range = 0.2,\n                                  height_shift_range = 0.2,\n                                  zoom_range = 0.2,\n                                  )\n\ntest_datagen = ImageDataGenerator()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T09:55:19.073653Z","iopub.execute_input":"2023-11-14T09:55:19.074078Z","iopub.status.idle":"2023-11-14T09:55:19.079220Z","shell.execute_reply.started":"2023-11-14T09:55:19.074045Z","shell.execute_reply":"2023-11-14T09:55:19.078042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(train_directory, \n                                       target_size= (224,224), \n                                       class_mode= 'binary',\n                                       color_mode= \"rgb\", \n                                       shuffle= True, \n                                       batch_size= 32)\n\nvalid_generator = test_datagen.flow_from_directory(validation_directory, \n                                       target_size= (224,224), \n                                       class_mode= 'binary',\n                                       color_mode= \"rgb\", \n                                       shuffle= True, \n                                       batch_size= 32)\n\ntest_generator = test_datagen.flow_from_directory(test_directory, \n                                       target_size= (224,224), \n                                       class_mode= 'binary',\n                                       color_mode= \"rgb\", \n                                       shuffle= False, \n                                       batch_size= 32)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T11:31:49.696524Z","iopub.execute_input":"2023-11-14T11:31:49.696926Z","iopub.status.idle":"2023-11-14T11:31:49.853184Z","shell.execute_reply.started":"2023-11-14T11:31:49.696885Z","shell.execute_reply":"2023-11-14T11:31:49.852425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = tf.keras.applications.VGG16(\n    include_top=False,  # Exclude the fully connected layers\n    weights='imagenet',\n    input_shape=(224, 224, 3)\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T09:57:23.054204Z","iopub.execute_input":"2023-11-14T09:57:23.054584Z","iopub.status.idle":"2023-11-14T09:57:28.161473Z","shell.execute_reply.started":"2023-11-14T09:57:23.054555Z","shell.execute_reply":"2023-11-14T09:57:28.160424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential,load_model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D ,BatchNormalization\n\nvgg_model = tf.keras.Sequential([\n    base_model,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Activation('relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nvgg_model.compile(\n    loss='binary_crossentropy',\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T09:57:39.492091Z","iopub.execute_input":"2023-11-14T09:57:39.492726Z","iopub.status.idle":"2023-11-14T09:57:39.633882Z","shell.execute_reply.started":"2023-11-14T09:57:39.492692Z","shell.execute_reply":"2023-11-14T09:57:39.632962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10 ,restore_best_weights = True)\ncheckpoint = ModelCheckpoint(\"Brain_Tumor_Model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')","metadata":{"execution":{"iopub.status.busy":"2023-11-14T09:58:07.560686Z","iopub.execute_input":"2023-11-14T09:58:07.561631Z","iopub.status.idle":"2023-11-14T09:58:07.568226Z","shell.execute_reply.started":"2023-11-14T09:58:07.561594Z","shell.execute_reply":"2023-11-14T09:58:07.567203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_history = vgg_model.fit(train_generator,verbose=1,callbacks = [early_stopping,checkpoint],epochs=50,validation_data=valid_generator)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T09:59:03.902165Z","iopub.execute_input":"2023-11-14T09:59:03.902565Z","iopub.status.idle":"2023-11-14T10:38:11.719417Z","shell.execute_reply.started":"2023-11-14T09:59:03.902531Z","shell.execute_reply":"2023-11-14T10:38:11.718408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" y_true_labels = test_generator.classes\n\ny_pred = vgg_model.predict(test_generator)\n\nthreshold = 0.5  \n\n# Convert the raw predictions to binary predictions\ny_pred_binary = (y_pred > threshold).astype(int)\n\n# Print the binary predictions\nprint(classification_report(y_pred_binary, y_true_labels))","metadata":{"execution":{"iopub.status.busy":"2023-11-14T11:32:27.452829Z","iopub.execute_input":"2023-11-14T11:32:27.453237Z","iopub.status.idle":"2023-11-14T11:32:30.373792Z","shell.execute_reply.started":"2023-11-14T11:32:27.453206Z","shell.execute_reply":"2023-11-14T11:32:30.372717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(y_pred_binary, y_true_labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T12:16:51.479744Z","iopub.execute_input":"2023-11-14T12:16:51.480118Z","iopub.status.idle":"2023-11-14T12:16:51.488542Z","shell.execute_reply.started":"2023-11-14T12:16:51.480087Z","shell.execute_reply":"2023-11-14T12:16:51.487648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nfrom ipywidgets import FileUpload, Output, VBox\nimport io\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\n\n# Create a file upload widget\nupload = FileUpload()\n\n# Create an output widget to display predictions\noutput = Output()\n\n# Load your model\nmy_model = load_model('Brain_Tumor_Model.h5')\n\n# Set a threshold for binary classification\nthreshold = 0.5\n\n# Function to handle file upload and prediction\ndef handle_upload(change):\n    with output:\n        # Clear previous output\n        output.clear_output()\n\n        # Get the uploaded file content\n        uploaded_file_content = list(upload.value.values())[0][\"content\"]\n\n        # Process the file content as needed (e.g., convert to image array)\n        img = Image.open(io.BytesIO(uploaded_file_content))\n\n        # Normalize the image by cropping (center crop)\n        h, w = img.size\n        crop_start_x = (w - 224) // 2\n        crop_start_y = (h - 224) // 2\n        img = img.crop((crop_start_x, crop_start_y, crop_start_x + 224, crop_start_y + 224))\n        img = img.resize((224, 224))\n\n        # Convert the image to a format suitable for model prediction\n        #img_array = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n        img_array = np.expand_dims(img, axis=0)\n\n        # Make predictions using your model\n        predictions = my_model.predict(img_array)\n\n        # Convert predictions to binary (0 or 1) based on the threshold\n        binary_prediction = 'Tumor Detected' if predictions[0][0] > threshold else 'No Tumor Detected'\n\n        # Print or use the binary prediction as needed\n        print(\"Prediction:\", binary_prediction)\n        \n        \n\n# Attach the handle_upload function to the change event of the upload widget\nupload.observe(handle_upload, names='_counter')\n\n# Display the widgets\nVBox([upload, output])","metadata":{"execution":{"iopub.status.busy":"2023-11-14T14:52:13.477210Z","iopub.execute_input":"2023-11-14T14:52:13.478146Z","iopub.status.idle":"2023-11-14T14:52:32.506254Z","shell.execute_reply.started":"2023-11-14T14:52:13.478104Z","shell.execute_reply":"2023-11-14T14:52:32.504739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink, FileLinks\nfrom google.colab import files\n\n# Add an upload button\nuploaded = files.upload()\n\n# Print the names of the uploaded files\nfor filename in uploaded.keys():\n    print(f'Uploaded file: {filename}')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T11:42:21.720952Z","iopub.execute_input":"2023-11-14T11:42:21.721700Z","iopub.status.idle":"2023-11-14T11:42:21.759539Z","shell.execute_reply.started":"2023-11-14T11:42:21.721668Z","shell.execute_reply":"2023-11-14T11:42:21.758374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_input_image(img):\n    # Normalize the image by cropping (center crop)\n    h, w = img.shape[:2]\n    crop_start_x = (w - 224) // 2\n    crop_start_y = (h - 224) // 2\n    img = img[crop_start_y:crop_start_y+224, crop_start_x:crop_start_x+224]\n    img = tf.image.resize(img, [224,224])\n    img = np.expand_dims(img, axis = 0)\n    \n    # Make predictions\n    model = tf.keras.models.load_model('Tumor_Model.h5')\n    prediction = model.predict(img)\n    result = 'No Tumor Detected' if prediction[0][0] > 0.5 else 'Tumor detected'\n    \n\n    return prediction","metadata":{},"execution_count":null,"outputs":[]}]}